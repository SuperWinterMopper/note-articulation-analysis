{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d863e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "from numpy.fft import fft, fftshift, fftfreq\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b363c140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "importlib.reload(helpers)\n",
    "\n",
    "# Driver\n",
    "class Ex:\n",
    "    def __init__(self, name: str, num_notes: int, spec_thresh: float, bpm: int, max_num_notes_per_beat: int):\n",
    "        self.name = name\n",
    "        self.num_notes = num_notes\n",
    "        self.spec_thresh = spec_thresh\n",
    "        self.bpm = bpm\n",
    "        self.max_num_notes_per_beat = max_num_notes_per_beat\n",
    "        self.min_time_between = 60 / (self.bpm * max_num_notes_per_beat)\n",
    "        self.sustain_thresh_coeff = 0\n",
    "\n",
    "def getExercises():\n",
    "    return [\n",
    "        Ex(\"ex1WholeMod.mp4\", num_notes=90, spec_thresh=.15, bpm=80, max_num_notes_per_beat=2),\n",
    "        Ex(\"ex1WholeModF.mp4\", num_notes=90, spec_thresh=.15, bpm=120, max_num_notes_per_beat=2),\n",
    "        Ex(\"ex2WholeMod.mp4\", num_notes=49, spec_thresh=.15, bpm=80, max_num_notes_per_beat=1),\n",
    "        Ex(\"ex3WholeMod.mp4\", num_notes=145, spec_thresh=.15, bpm=100, max_num_notes_per_beat=2),\n",
    "        Ex(\"ex3WholeModF.mp4\", num_notes=145, spec_thresh=.15, bpm=130, max_num_notes_per_beat=2),\n",
    "        Ex(\"ex4WholeMod.mp4\", num_notes=102, spec_thresh=.15, bpm=90, max_num_notes_per_beat=4),\n",
    "        Ex(\"ex4WholeModF.mp4\", num_notes=102, spec_thresh=.05, bpm=120, max_num_notes_per_beat=2),\n",
    "        Ex(\"ex5WholeMod.mp4\", num_notes=133, spec_thresh=.15, bpm=64, max_num_notes_per_beat=2),\n",
    "        Ex(\"ex5WholeModF.mp4\", num_notes=133, spec_thresh=.15, bpm=86, max_num_notes_per_beat=2),\n",
    "        Ex(\"ex6WholeMod.mp4\", num_notes=118, spec_thresh=.15, bpm=70, max_num_notes_per_beat=4),\n",
    "        Ex(\"ex6WholeModF.mp4\", num_notes=118, spec_thresh=.15, bpm=90, max_num_notes_per_beat=4),\n",
    "        Ex(\"ex7WholeMod.mp4\", num_notes=86, spec_thresh=.15, bpm=70, max_num_notes_per_beat=2),\n",
    "        Ex(\"ex8WholeMod.mp4\", num_notes=112, spec_thresh=.15, bpm=55, max_num_notes_per_beat=4),\n",
    "        Ex(\"ex8WholeModF.mp4\", num_notes=112, spec_thresh=.15, bpm=80, max_num_notes_per_beat=4),\n",
    "        Ex(\"ex9WholeMod.mp4\", num_notes=121, spec_thresh=.15, bpm=100, max_num_notes_per_beat=4),\n",
    "        Ex(\"ex10WholeMod.mp4\", num_notes=102, spec_thresh=.15, bpm=120, max_num_notes_per_beat=3)\n",
    "    ]\n",
    "\n",
    "def observe_accuracy():\n",
    "    avg_artic_leng = 0\n",
    "    exerciseNoteCounts = getExercises()\n",
    "\n",
    "    for ex in exerciseNoteCounts:\n",
    "        exercise = ex.name\n",
    "        note_count = ex.num_notes\n",
    "        spec_thresh = ex.spec_thresh\n",
    "        min_time_between = ex.min_time_between * .8\n",
    "        sustain_thresh = ex.sustain_thresh_coeff * spec_thresh\n",
    "\n",
    "        ys, ts, sr = helpers.get_audio_data(f\"exercises/{exercise}\")\n",
    "        ts_fr, fr_freq_amps, freq_bins = helpers.magnitude_spectrogram(ys, ts, sr)\n",
    "        ts_fr, spec_flux = helpers.compute_spectral_flux(ts_fr, fr_freq_amps, sr)\n",
    "\n",
    "        centroids = helpers.compute_spectral_centroid(time_frames=ts_fr, freq_bins=freq_bins, frame_freq_amps=fr_freq_amps)\n",
    "        \n",
    "        plt.title(exercise)\n",
    "        plt.xlabel(\"Time (s)\"); plt.ylabel(\"Spectral Flux\")\n",
    "        plt.plot(ts_fr, spec_flux, c=\"orange\")\n",
    "        img_path = Path.cwd() / \"spec_flux_graphs\" / f\"{exercise} Spectral Flux.png\"\n",
    "        plt.savefig(img_path)\n",
    "        plt.close()\n",
    "        \n",
    "        # onsets = helpers.detect_onsets(spec_flux, ts_fr, threshold=spec_thresh, min_time_between=min_time_between)\n",
    "        onsets, sustains = helpers.detect_onsets_and_release(spec_flux=spec_flux, times=ts_fr, sr=sr, sustain_thresh=sustain_thresh, onset_thresh=spec_thresh, min_time_between=min_time_between)\n",
    "\n",
    "        print_num_onset_detection_accuracy = True\n",
    "        graph_onsets_sustains = True\n",
    "        \n",
    "        if print_num_onset_detection_accuracy:\n",
    "            print(f\"For exercise {exercise}, Note count Actual:\\t{note_count}, Note count Detected: \\t{len(onsets)} | Accuracy: \\t{min(note_count / len(onsets), len(onsets) / note_count)}\")\n",
    "\n",
    "        if graph_onsets_sustains:\n",
    "            artic_lens = [sustains[i] - onsets[i] for i in range(min(len(onsets), len(sustains)))]\n",
    "            # if np.max(artic_lens) > 1:\n",
    "            # print(f\"For {exercise}, min articulation length: {np.min(artic_lens)}\")\n",
    "            # if np.max(artic_lens) > .1:\n",
    "            #     print(\"==============================================================\")\n",
    "            #     print(f\"For {exercise}, max articulation length: {np.max(artic_lens)}\")\n",
    "            print(f\"For {exercise}, mean articulation length: {np.average(artic_lens)}\")\n",
    "            avg_artic_leng += np.average(artic_lens)\n",
    "\n",
    "            onset_indic = np.zeros_like(ts_fr)\n",
    "            sustain_indic = np.zeros_like(ts_fr)\n",
    "\n",
    "            stem_top = np.max(centroids)\n",
    "\n",
    "            # Set 1.0 at the closest time points where onsets/sustains occur\n",
    "            for onset_time in onsets:\n",
    "                idx = np.argmin(np.abs(ts_fr - onset_time))\n",
    "                onset_indic[idx] = stem_top\n",
    "                \n",
    "            for sustain_time in sustains:\n",
    "                idx = np.argmin(np.abs(ts_fr - sustain_time))\n",
    "                sustain_indic[idx] = stem_top\n",
    "\n",
    "            plt.title(f\"{exercise} Onset + Sustain + Spectral Centroid\")\n",
    "            plt.xlim(10, 14)\n",
    "            plt.xlabel(\"Times (s)\")\n",
    "            plt.stem(ts_fr, onset_indic, linefmt='--', markerfmt='pink', label='Onsets')\n",
    "            plt.stem(ts_fr, sustain_indic, linefmt='--', markerfmt='red', label='Sustains')\n",
    "            plt.legend()\n",
    "            img_path = Path.cwd() / \"centroids\" / f\"{exercise} centroid.png\"\n",
    "            plt.plot(ts_fr, centroids)\n",
    "            plt.savefig(img_path)\n",
    "            plt.close()\n",
    "\n",
    "    print(f\"Average articulation window size is {avg_artic_leng / len(exerciseNoteCounts)}\")\n",
    "\n",
    "# observe_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "977a7e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for exercise ex1WholeMod.mp4, note onset spectral threshold is 0.08030303030303029\n",
      "for exercise ex1WholeModF.mp4, note onset spectral threshold is 0.15545454545454546\n",
      "for exercise ex2WholeMod.mp4, note onset spectral threshold is 0.11424242424242424\n",
      "for exercise ex3WholeMod.mp4, note onset spectral threshold is 0.08\n",
      "for exercise ex3WholeModF.mp4, note onset spectral threshold is 0.08\n",
      "for exercise ex4WholeMod.mp4, note onset spectral threshold is 0.18696969696969698\n",
      "for exercise ex4WholeModF.mp4, note onset spectral threshold is 0.08\n",
      "for exercise ex5WholeMod.mp4, note onset spectral threshold is 0.10212121212121211\n",
      "for exercise ex5WholeModF.mp4, note onset spectral threshold is 0.10454545454545454\n",
      "for exercise ex6WholeMod.mp4, note onset spectral threshold is 0.10212121212121211\n",
      "for exercise ex6WholeModF.mp4, note onset spectral threshold is 0.11424242424242424\n",
      "for exercise ex7WholeMod.mp4, note onset spectral threshold is 0.1215151515151515\n",
      "for exercise ex8WholeMod.mp4, note onset spectral threshold is 0.11666666666666665\n",
      "for exercise ex8WholeModF.mp4, note onset spectral threshold is 0.11909090909090908\n",
      "for exercise ex9WholeMod.mp4, note onset spectral threshold is 0.08\n",
      "for exercise ex10WholeMod.mp4, note onset spectral threshold is 0.14333333333333334\n",
      "[<__main__.Ex object at 0x000001F7D118B370>, <__main__.Ex object at 0x000001F7D118B2B0>, <__main__.Ex object at 0x000001F7D11883A0>, <__main__.Ex object at 0x000001F7D1189510>, <__main__.Ex object at 0x000001F7D1189540>, <__main__.Ex object at 0x000001F7D118AFE0>, <__main__.Ex object at 0x000001F7D1188520>, <__main__.Ex object at 0x000001F7D118AE90>, <__main__.Ex object at 0x000001F7D1189840>, <__main__.Ex object at 0x000001F7D11887C0>, <__main__.Ex object at 0x000001F7D118B160>, <__main__.Ex object at 0x000001F7D118A590>, <__main__.Ex object at 0x000001F7D1189DB0>, <__main__.Ex object at 0x000001F7D118A290>, <__main__.Ex object at 0x000001F7D11898A0>, <__main__.Ex object at 0x000001F7D1189A20>]\n"
     ]
    }
   ],
   "source": [
    "def optimize_spec_thresh():\n",
    "    lowest, highest, num_tests = .01, .25, 100\n",
    "    spec_thres_vals = np.linspace(lowest, highest, num_tests)\n",
    "    opt_spec_thresh = [] # the optimized thresholds for each exercise\n",
    "\n",
    "    exerciseNoteCounts = getExercises()\n",
    "\n",
    "    for ex in exerciseNoteCounts:\n",
    "        exercise = ex.name\n",
    "        note_count = ex.num_notes\n",
    "        min_time_between = ex.min_time_between * .8\n",
    "\n",
    "        num_onsets_detected = []\n",
    "        accuracies = []\n",
    "\n",
    "        ys, ts, sr = helpers.get_audio_data(f\"exercises/{exercise}\")\n",
    "        ts_fr, fr_freq_amps, _ = helpers.magnitude_spectrogram(ys, ts, sr)\n",
    "        ts_fr, spec_flux = helpers.compute_spectral_flux(ts_fr, fr_freq_amps, sr)\n",
    "\n",
    "        for spec_thresh in spec_thres_vals:\n",
    "            onsets = helpers.detect_onsets_only(spec_flux=spec_flux, times=ts_fr, sr=sr, onset_thresh=spec_thresh, min_time_between=min_time_between)\n",
    "            accuracy = min(note_count / len(onsets), len(onsets) / note_count)\n",
    "\n",
    "            num_onsets_detected.append(len(onsets))\n",
    "            accuracies.append(accuracy)\n",
    "        \n",
    "        plt.title(f\"{exercise} Spectral Flux Threshold vs Number of Onsets Detected\")\n",
    "        plt.xlabel(\"Spectral Flux Threshold\"); plt.ylabel(\"Number of Onsets Detected\")\n",
    "        plt.plot(spec_thres_vals, num_onsets_detected, label=\"Threshold vs Onsets\")\n",
    "        plt.axhline(y=note_count, color='limegreen', linestyle='--', linewidth=2, label=\"Correct # Onsets\")\n",
    "        plt.legend()\n",
    "        img_path = Path.cwd() / \"spec_thresh_opt\" / \"graphs\" / f\"{exercise}.png\"\n",
    "        plt.savefig(img_path)\n",
    "        plt.close()\n",
    "\n",
    "        opt_perf = max(accuracies)\n",
    "        opt_perf_spec_thresh = [spec_thres_vals[i] for i, val in enumerate(accuracies) if val == opt_perf]\n",
    "        with open(\"spec_thresh_opt/optimized_values.txt\", \"a\") as f:\n",
    "            f.write(f\"{'=' * 30}\\n\")\n",
    "            f.write(f\"Best performing spectral thresholds at {opt_perf * 100}% accuracy for {exercise}:\\n\")\n",
    "            f.write(f\"{opt_perf_spec_thresh}\\n\\n\")\n",
    "\n",
    "        opt_spec_thresh.append(opt_perf_spec_thresh[len(opt_perf_spec_thresh) // 2]) # choose the middle most successful output to maximize applicability\n",
    "        \n",
    "    minimum_thresh = .08 # optimizing for the best threshold for this case hurts sustain onset detection, so this ensures a decent middle ground.\n",
    "    for i, ex in enumerate(exerciseNoteCounts):\n",
    "        ex.spec_thresh = max(opt_spec_thresh[i], minimum_thresh)\n",
    "\n",
    "    return exerciseNoteCounts\n",
    "\n",
    "opt_exercises = optimize_spec_thresh()\n",
    "for ex in opt_exercises:\n",
    "    print(f\"for exercise {ex.name}, note onset spectral threshold is {ex.spec_thresh}\")\n",
    "print(opt_exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2a7567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_sustain_thresh_coeff(exercises):\n",
    "    # lowest, highest, num_tests = -.01, .85, 100\n",
    "    lowest, highest, num_tests = 0, 1, 100\n",
    "    sustain_thresh_coeffs = np.linspace(lowest, highest, num_tests)\n",
    "    opt_coeffs = [] # the optimized coefficients for each exercise\n",
    "\n",
    "    for ex in exercises:\n",
    "        exercise = ex.name\n",
    "        note_count = ex.num_notes\n",
    "        spec_thresh = ex.spec_thresh\n",
    "        min_time_between = ex.min_time_between * .8\n",
    "\n",
    "        sustain_saturations = []\n",
    "\n",
    "        ys, ts, sr = helpers.get_audio_data(f\"exercises/{exercise}\")\n",
    "        ts_fr, fr_freq_amps, _ = helpers.magnitude_spectrogram(ys, ts, sr)\n",
    "        ts_fr, spec_flux = helpers.compute_spectral_flux(ts_fr, fr_freq_amps, sr)\n",
    "\n",
    "        for coeff in sustain_thresh_coeffs:\n",
    "            sustain_thresh = spec_thresh * coeff\n",
    "            _, sustains = helpers.detect_onsets_and_release(spec_flux=spec_flux, times=ts_fr, sr=sr, onset_thresh=spec_thresh, sustain_thresh=sustain_thresh, min_time_between=min_time_between)\n",
    "\n",
    "            sustain_saturations.append(len(sustains) / note_count)\n",
    "\n",
    "        plt.title(f\"{exercise} Coefficient for Sustain vs Onset Pairing Completeness\")\n",
    "        plt.xlabel(\"Coefficient for Sustain\"); plt.ylabel(\"Onset Pairing Completeness\")\n",
    "        plt.plot(sustain_thresh_coeffs, sustain_saturations)\n",
    "        img_path = Path.cwd() / \"sustain_thresh_opt\" / \"graphs\" / f\"{exercise}.png\"\n",
    "        plt.savefig(img_path)\n",
    "        plt.close()\n",
    "    \n",
    "        opt_perf_sustain_coeff = [sustain_thresh_coeffs[i] for i, val in enumerate(sustain_saturations) if val == max(sustain_saturations)]\n",
    "        \n",
    "        with open(\"sustain_thresh_opt/optimized_values.txt\", \"a\") as f:\n",
    "            f.write(f\"{'=' * 30}\\n\")\n",
    "            f.write(f\"Minimum coefficient for complete onset + sustain pairing for {exercise}:\\n\")\n",
    "            f.write(f\"{np.min(opt_perf_sustain_coeff)}\\n\\n\")\n",
    "\n",
    "        opt_coeffs.append(np.min(opt_perf_sustain_coeff) * 1.1) # choose the minimum most successful output which is closest to ideal best\n",
    "\n",
    "    for i, ex in enumerate(exercises):\n",
    "        ex.sustain_thresh_coeff = opt_coeffs[i]\n",
    "        \n",
    "    return exercises\n",
    "\n",
    "opt_exercises = optimize_sustain_thresh_coeff(opt_exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeddaf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"opt_results.txt\", \"w\") as f: \n",
    "    f.write(\"FINAL OPTIMIZED PARAMETERS FOR EACH EXERCISE\\n\\n\")\n",
    "    for ex in opt_exercises:\n",
    "        f.write(f\"{'=' * 50}\\n\")\n",
    "        f.write(f\"Name: \\t {ex.name}\\n\")\n",
    "        f.write(f\"Note Count: \\t {ex.num_notes}\\n\")\n",
    "        f.write(f\"Spectral Threshold: \\t {ex.spec_thresh:.4f}\\n\")\n",
    "        f.write(f\"BPM: \\t {ex.bpm}\\n\")\n",
    "        f.write(f\"Max Notes Per Beat: \\t {ex.max_num_notes_per_beat}\\n\")\n",
    "        f.write(f\"Min Time Between Notes: \\t {ex.min_time_between:.4f} seconds\\n\")\n",
    "        f.write(f\"Sustain Threshold Coefficient: \\t {ex.sustain_thresh_coeff:.4f}\\n\")\n",
    "        f.write(f\"Sustain Threshold Value: \\t {ex.spec_thresh * ex.sustain_thresh_coeff:.4f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc2e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.01010101 0.02020202 0.03030303 0.04040404 0.05050505\n",
      " 0.06060606 0.07070707 0.08080808 0.09090909 0.1010101  0.11111111\n",
      " 0.12121212 0.13131313 0.14141414 0.15151515 0.16161616 0.17171717\n",
      " 0.18181818 0.19191919 0.2020202  0.21212121 0.22222222 0.23232323\n",
      " 0.24242424 0.25252525 0.26262626 0.27272727 0.28282828 0.29292929\n",
      " 0.3030303  0.31313131 0.32323232 0.33333333 0.34343434 0.35353535\n",
      " 0.36363636 0.37373737 0.38383838 0.39393939 0.4040404  0.41414141\n",
      " 0.42424242 0.43434343 0.44444444 0.45454545 0.46464646 0.47474747\n",
      " 0.48484848 0.49494949 0.50505051 0.51515152 0.52525253 0.53535354\n",
      " 0.54545455 0.55555556 0.56565657 0.57575758 0.58585859 0.5959596\n",
      " 0.60606061 0.61616162 0.62626263 0.63636364 0.64646465 0.65656566\n",
      " 0.66666667 0.67676768 0.68686869 0.6969697  0.70707071 0.71717172\n",
      " 0.72727273 0.73737374 0.74747475 0.75757576 0.76767677 0.77777778\n",
      " 0.78787879 0.7979798  0.80808081 0.81818182 0.82828283 0.83838384\n",
      " 0.84848485 0.85858586 0.86868687 0.87878788 0.88888889 0.8989899\n",
      " 0.90909091 0.91919192 0.92929293 0.93939394 0.94949495 0.95959596\n",
      " 0.96969697 0.97979798 0.98989899 1.        ]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSP_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
